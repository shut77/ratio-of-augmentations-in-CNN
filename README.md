# Исследование влияния аугментаций на работу CNN  
В этом проекте исследуется влияние различных техник аугментации данных на эффективность сверточных нейронных сетей на датасете Intel Image Classification  

## 📌 Оглавление

1.  [Цель проекта](#-цель-проекта)
2.  [Датасет](#-датасет)
3.  [Архитектура модели](#-архитектура-модели)
4.  [Методология](#-методология)
5.  [Результаты и графики](#-результаты-и-графики)
6.  [Ключевые выводы](#-ключевые-выводы)


## 🎯 Цель проекта

Цель проекта - изучение того, как различные техники аугментации данных и их соотношение с исходными данными влияют на качество обучения сверточных нейронных сетей.  


## 📊 Датасет

*   **Выбранный датасет:** Intel Image Classification - это изображения природных ландшафтов по всему миру.  
*   **Ссылка:** [https://www.kaggle.com/datasets/puneet6060/intel-image-classification]  
*   **Описание:** Данные содержат около 25 тысяч изображений размером 150x150, распределенных по 6 категориям.
*   **Разделение данных:** В Train около 14 тыс. изображений, в Test - 3 тыс., а в Prediction - 7 тыс.

## 🧠 Архитектура модели

Базовая CNN модель была реализована "с нуля" с использованием PyTorch.
**Структура модели:**
  - Сверточные блоки: 3 последовательных слоя (Conv2d + BatchNorm + Activation + MaxPool)  
  - Адаптивный пулинг приводит feature map к фиксированному размеру 8x8.  
  - Классификатор из двух линейных слоев, который преобразует признаки в 6-мерный вектор логитов (для 6 классов).

 
## 🧪 Методология

Исследование проводилось в 5 этапов с постепенным добавлением техник аугментации:

1.  **Базовые геометрические преобразования:** Horizontal Flip, Rotation (±15°)
2.  **Добавление искажений:** Zoom (±10%), Translation (±10%)
3.  **Цветовые преобразования:** Brightness (±20%), Contrast (±20%)
4.  **Продвинутые техники:** Gaussian Blur, Noise Injection
5.  **Современные аугментации:** Cutout, MixUp

**Соотношения данных:** Для каждого этапа тестировались 5 соотношений аугментированных данных к исходным: `0%`, `25%`, `50%`, `75%`, `100%`.  


## 📈 Результаты и графики

### Базовые метрики (Baseline)
*   **Accuracy:** `0.8496`
*   **F1-Score:** `0.8488`

<p align="center">
  <img width="700" alt="этап 4" src="https://github.com/user-attachments/assets/c602a52b-9f35-4978-90c3-1a57dc1e920c">
  <br>
  <em>Рис. 1: Этап 4.</em>
</p>
  
<p align="center">
  <img width="700" alt="этап 4" src="https://github.com/user-attachments/assets/087a41ad-22af-4024-9191-2a58fe3a36dd">
  <br>
  <em>Рис. 2: Этап 4. Loss и Accuracy на Train </em>
</p>
  
<p align="center">
  <img width="600" alt="этап 4" src="https://github.com/user-attachments/assets/fc0dbf40-4b4f-4699-83b0-9b0ed2cd85b8">
  <br>
  <em>Рис. 3: Этап 4. HeatMap </em>
</p>
  
<p align="center">
  <img width="600" alt="этап 4" src="https://github.com/user-attachments/assets/34570f9c-7fa6-4744-be79-edd17dd73c5f">
  <br>
  <em>Рис. 4: Confusion Matrix для лучшей модели </em>
</p>

## 🧾 Ключевые выводы
1) Лучший результат показала модель без аугментаций.
2) Loss в процессе обучения монотонно уменьшается, Accuracy растет -  причем и то и то не выходят на ассимптотику, поэтому стоит добавить еще эпох.
3) Наибольшее количество ошибок модель допускает в классах "building" и "street".  
4) На первых двух этапах аугментации можно получить прирост качества -  оптимальное соотношение - 0.25/0.75 (наибольший прирост на первом этапе) или 50/50. Последующие, более сложные аугментации (этапы 3-5) систематически снижают accuracy, поэтому их применение не рекомендуется.





